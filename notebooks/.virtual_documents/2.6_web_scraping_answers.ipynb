



























































!pip install requests beautifulsoup4








import requests

url = "https://www.decathlon.com/collections/mountain-bikes"
response = requests.get(url)
response





response.content


response.headers # Response headers (as a Python dictionary)


print(response.headers['Content-Type'])








from bs4 import BeautifulSoup

soup = BeautifulSoup(response.content, "html.parser")





type(soup)


print(soup.prettify())  # This formats the HTML in a readable way




















soup.find("title") # Find the first <title> tag on the page


soup.find_all("title") # Find the all <title> tags on the page

















soup.find_all(class_='de-ProductTile-title')




















# Find all <h4> tags with class "de-ProductTile-title"
bike_names_tags = soup.find_all('h4', class_='de-ProductTile-title')
bike_names_tags


# find_all returns a list
bike_names_tags[:3]


type(bike_names_tags) # What type is it?


# Lets look at how many elements we retrieved
len(bike_names_tags)


# Lets look at the first element
bike_names_tags[0]


# We can get the actual text using .text, .getText() or .get_text()
print(bike_names_tags[0].text)
print(bike_names_tags[0].getText())
print(bike_names_tags[0].get_text())


# Lets get rid of all the white spaces
bike_names_tags[0].getText().strip()


# Create a new list only with bicycle names
names = [bike.text.strip() for bike in bike_names_tags]
names





# Find the <span> tag and get its text
prices = soup.find_all('span', class_='js-de-ProductTile-currentPrice')
prices


prices[0].text


for price_tag in prices:
    print(price_tag.text)











# Find the <a> tag and get its href attribute
#print(soup.find('a', class_='de-u-linkClean js-de-ProductTile-link'))#.get('href')
print(soup.find('a', class_='js-de-ProductTile-link').get("href"))
print(soup.find('a', class_='js-de-ProductTile-link')["href"])


# Extracting all links within <a> tags and class 'de-u-linkClean js-de-ProductTile-link'
for link in soup.find_all('a', class_='js-de-ProductTile-link'):
    print(link.get('href'))











# Find all <div> and <span> tags
soup.find_all(['div', 'span'])








# Find all elements with class 'js-de-ProductTile-currentPrice' or 'de-ProductTile-title'
soup.find_all(class_=['js-de-ProductTile-currentPrice', 'de-ProductTile-title'])








# Find all <h4> or <span> tags with class "class1" or "class2"
soup.find_all(['h4', 'span'], attrs={"class": ['js-de-ProductTile-currentPrice', 'de-ProductTile-title']})








# Only get the first 5 <h4> tags
soup.find_all('h4', limit=5)





soup.div.find_all("h4")





soup.div.find_all("h4")[1]








import pandas as pd

# Lists to store extracted data
bicycle_names = []
prices = []

# Find all components
components = soup.find_all('div', class_='de-ProductTile-info')

for component in components:
    # Extract bicycle name
    #component
    bike_name = component.find('h4', class_='de-ProductTile-title').text.strip()
    bicycle_names.append(bike_name)

    # Extract price
    price = component.find('span', class_='js-de-ProductTile-currentPrice').text.strip().replace("$", "")
    prices.append(price)

# Create DataFrame
df = pd.DataFrame({
    'Bicycle_Name': bicycle_names,
    'Price': prices
})

df











def extract_bike_info(soup):
    # Lists to store extracted data
    bicycle_names = []
    prices = []
    url_product_details = []
    url_product_images = []

    # Find all components
    components = soup.find_all('div', class_='de-ProductTile-info')

    for component in components:
        # Extract bicycle name
        #component
        bike_name = component.find('h4', class_='de-ProductTile-title').text.strip()
        bicycle_names.append(bike_name)

        # Extract price
        price = component.find('span', class_='js-de-ProductTile-currentPrice').text.strip().replace("$", "")
        prices.append(price)

        # Product details
        url_details = component.find('a', class_='de-u-linkClean js-de-ProductTile-link js-de-ProductTile-box').get("href")
        url_product_details.append(url_details)

        # Product image
        product_image = component.find('img').get('data-src')
        url_product_images.append("https:"+product_image)

    # Create DataFrame
    df = pd.DataFrame({
        'Bicycle_Name': bicycle_names,
        'Price': prices,
        'Details': url_product_details,
        'Image': url_product_images
        })
    return df


df = extract_bike_info(soup)
df








pages = [f"https://www.decathlon.com/collections/deals?page={pag}" for pag in range(1,5)]


pages


def get_df_from_url(url):

    response = requests.get(url)

    soup = BeautifulSoup(response.content, 'html.parser')
    df = extract_bike_info(soup)
    return df


dfs = [get_df_from_url(p) for p in pages]


dfs[1]


# Concatenate all DataFrames in the list
result_df = pd.concat(dfs, ignore_index=True)
result_df




















soup.select("article")





soup.select(".de-ProductTile")








# Extracting all links within <a> tags and class 'de-u-linkClean js-de-ProductTile-link'
for index, link in enumerate(soup.find_all('a', class_='js-de-ProductTile-link')):
    if index%2 == 0:
        print(link.get('href'))





# Extracting all links within <a> tags and class 'de-u-linkClean js-de-ProductTile-link'
for link in soup.select('a.de-u-linkClean.js-de-ProductTile-link'):
    print(link.get('href'))





soup.select(".de-ProductTile .de-ProductTile-title")


soup.select("article h4")


# how many spans?
len(soup.select("span"))


# how many spans inside spans?
len(soup.select("span span"))


# how many spans inside spans inside spans?
len(soup.select("span span span"))


# how many span inside div inside div inside div ...
len(soup.select("div div div div div div div div span"))








first_product = soup.find('article', class_='de-ProductTile')
first_product.select('h4.de-ProductTile-title')


# Since its a list we need to access the element to get the text
first_product.select('h4.de-ProductTile-title')[0].text














response = requests.get("https://www.bbc.com/")
response


soup = BeautifulSoup(response.content, "html.parser")


img_tags = soup.find_all("img") # We get all the image elements


len(img_tags) # Lets see how many we got


img_tags[1] # For example, lets look at the second one to see how we can get the actual URL


# We can use the get method to get the src attribute which contains the URL to the image
img_tags[1].get("src")


# Find the nav element with the specified class
nav_element = soup.find('nav', class_='orbit-header-links international')

# Find all span elements inside the nav element
menu_names = [span.get_text() for span in nav_element.find_all('span')]

# Print the menu names
for name in menu_names:
    print(name)





















